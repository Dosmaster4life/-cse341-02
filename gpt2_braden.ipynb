{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dosmaster4life/-cse341-02/blob/main/gpt2_braden.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Medium article\n",
        "https://medium.com/ai-innovation/beginners-guide-to-retrain-gpt-2-117m-to-generate-custom-text-content-8bb5363d8b7f"
      ],
      "metadata": {
        "id": "gaagNjUkNhKW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7ixEFgNL4cF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecd08450-e32d-45a7-fb64-5caa280e7506"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'gpt-2' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/nshepperd/gpt-2.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fire\n",
        "!pip install toposort"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EUAmIUsM9FR",
        "outputId": "2016b0cf-5814-4f97-b5c4-20ce02cc409a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.8/dist-packages (0.4.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from fire) (2.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from fire) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: toposort in /usr/local/lib/python3.8/dist-packages (1.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fire\n",
        "import regex\n",
        "import requests\n",
        "import tqdm\n",
        "import toposort"
      ],
      "metadata": {
        "id": "zhq74YSjMEAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python gpt-2/download_model.py 117M"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-XmwBWANJOo",
        "outputId": "ca67de63-fe1b-4065-f428-09bd07781d10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching checkpoint: 1.00kit [00:00, 1.07Mit/s]                                                     \n",
            "Fetching encoder.json: 1.04Mit [00:00, 2.44Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 1.13Mit/s]                                                   \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:23, 21.1Mit/s]                                  \n",
            "Fetching model.ckpt.index: 6.00kit [00:00, 4.12Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 472kit [00:00, 1.65Mit/s]                                                 \n",
            "Fetching vocab.bpe: 457kit [00:00, 1.58Mit/s]                                                       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv gpt-2/train.py gpt-2/src\n",
        "!mv gpt-2/encode.py gpt-2/src"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2dU1dqqN7lY",
        "outputId": "b4e90494-32e5-4eca-9372-65fd19132ca7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat 'gpt-2/train.py': No such file or directory\n",
            "mv: cannot stat 'gpt-2/encode.py': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/austen/austen.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGyERRZ1Oqj2",
        "outputId": "5b19e1ed-eea5-42d4-feb1-a5e80a60f04a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-02 19:14:33--  https://raw.githubusercontent.com/byui-cse/cse450-course/master/data/austen/austen.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4949262 (4.7M) [text/plain]\n",
            "Saving to: ‘austen.txt.1’\n",
            "\n",
            "\rausten.txt.1          0%[                    ]       0  --.-KB/s               \rausten.txt.1        100%[===================>]   4.72M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2022-12-02 19:14:33 (101 MB/s) - ‘austen.txt.1’ saved [4949262/4949262]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python gpt-2/src/encode.py austen.txt austen.npz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWsv37y2O31W",
        "outputId": "21b6df4f-4196-454c-8c17-ba094fbe06dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading files\n",
            "100% 1/1 [00:06<00:00,  6.23s/it]\n",
            "Writing austen.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, the model saves the checkpoint every 1000 steps"
      ],
      "metadata": {
        "id": "LPAzTJ_DP7Av"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python gpt-2/src/train.py --dataset austen.npz --model_name 117M"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2McxzHLvPFfI",
        "outputId": "9f565210-6821-4136-b0a4-2952507c497e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-02 19:21:54.426891: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "Using Adam optimizer\n",
            "Loading checkpoint checkpoint/run1/model-91\n",
            "Loading dataset...\n",
            "100% 1/1 [00:00<00:00, 23.76it/s]\n",
            "dataset has 1242655 tokens\n",
            "Training...\n",
            "[92 | 2.52] loss=3.45 avg=3.45\n",
            "[93 | 2.95] loss=3.23 avg=3.34\n",
            "[94 | 3.39] loss=3.38 avg=3.35\n",
            "[95 | 3.82] loss=3.49 avg=3.39\n",
            "[96 | 4.25] loss=2.94 avg=3.30\n",
            "[97 | 4.69] loss=3.47 avg=3.32\n",
            "[98 | 5.13] loss=3.32 avg=3.32\n",
            "[99 | 5.56] loss=3.21 avg=3.31\n",
            "Generating samples...\n",
            "======== SAMPLE 1 ========\n",
            " in his hand is a piece of paper, as when he gave me the book, the only object of my interest was in the object of discovering what I could and could not teach him. On the other hand, I knew nothing of the subject of the book except his opinions; but I found in the writing the most interesting, and I thought the subject very worthy of being taught.\n",
            "\n",
            "Thence to the door, and there I had a talk with Mr. Gaudet, who was a very kind fellow. He did indeed do justice not to their style; but I did not like the idea of it, and so I did not speak much. He was very very very kind towards me. The conversation that followed was very general, and I felt very pleased to think that Miss Bertram might be of interest to me at this present moment, because she and I met often in my chamber, and were always so much in touch. I recollected that Mr. Henry, who was very much interested in my business, was so happy to see me. I could scarcely say how much he would think of them both, except he said to me there was a great deal to be pleased about. At the table my heart sunk, and I did not suppose, as they spoke for a few minutes, that I must be obliged to hear it, but I could not refrain from speaking from the truth; and, as for the rest, they said nothing for any more time.\n",
            "\n",
            "We were in the chamber, but not sitting very far apart, and there came a knock at our door that seemed, indeed, nothing but the knocking. I came into it, but the doors were opened.\n",
            "\n",
            "The knocking had been for several moments, and I was so happy it seemed to have stopped me there. Mrs. Charles seemed in a very bad humour, and she did not go away; but, after a few minutes, she came out of the room altogether, and there was some talk of some other matter after they had been so long.\n",
            "\n",
            "\"I cannot be allowed to speak to you in such a way,\" said Mrs. Charles, \"but I know nothing about it.\"\n",
            "\n",
            "To my surprise, she was surprised to find her thoughts on the subject of business, but a moment ago she thought I must rather want to speak to them. She saw me with her eyes closed, and her heart was glad.\n",
            "\n",
            "My dear Miss Bertram had asked that I should go with her to the office, and we parted.\n",
            "\n",
            "My heart was happy for seeing you, Mr. Henry, and I, though very much in need of having a good dinner, to be sure is not one that is in my power to do. But the good dinner was not a very agreeable thing to me. The people are very kind, but I am a quiet-headed fellow, and I do not know whether I will be much troubled by it, or not with a pleasant, pleasant dinner in London. I thought Mr. Henry and Miss Bertram very much in love to the very end of their acquaintance; but Miss Bertram was in a strange situation, that I should be so much happy to see. That I should take the opportunity was a pretty real matter, for what she had done, or what I had said, in speaking of business, had always been very little.\n",
            "\n",
            "I did not regret saying anything, but the very mention of her being in the office, to the delight of my friends, was very good. I had not so much thought her in this manner as I wanted her in this, where they had never met, in my life. They would have the same feelings of curiosity and curiosity. They would have seen and talked without being disturbed by the talk, and would be sure not to complain.\n",
            "\n",
            "They came and sat, and they began to talk. They had been so long to talk; and at last, as they talked, their thoughts were so lively and agreeable, that one thing seemed to be forgotten.\n",
            "\n",
            "\"What is it?\" said they.\n",
            "\n",
            "For some minutes I felt a pleasure to read, but not much to do with them.\n",
            "\n",
            "\"You were told the story of the family. I have not seen you in a long time till they were so happy in your company. How did they live? How do you know them?\"\n",
            "\n",
            "They could not answer any of that.\n",
            "\n",
            "\"I know not how to name you,\" said Mrs. Charles, \"what you are, and who you are. A good many of the family belong to my father, and I have an idea to call you to be his father, but you will be found very little of your name there. For some time you have been heard to refer to them on the road, and they always go away together.\"\n",
            "\n",
            "They looked at me, and said \"Well done, gentlemen,\" and gave us every compliment, saying \"I am sorry, I thought not of you in conversation with your father, but you\n",
            "\n",
            "[100 | 19.35] loss=3.30 avg=3.31\n",
            "[101 | 19.79] loss=3.35 avg=3.31\n",
            "[102 | 20.24] loss=3.45 avg=3.33\n",
            "[103 | 20.67] loss=3.26 avg=3.32\n",
            "[104 | 21.11] loss=3.30 avg=3.32\n",
            "[105 | 21.55] loss=3.22 avg=3.31\n",
            "[106 | 22.00] loss=2.94 avg=3.28\n",
            "[107 | 22.44] loss=3.34 avg=3.29\n",
            "[108 | 22.88] loss=3.19 avg=3.28\n",
            "[109 | 23.32] loss=3.67 avg=3.31\n",
            "[110 | 23.77] loss=3.41 avg=3.31\n",
            "[111 | 24.21] loss=3.24 avg=3.31\n",
            "[112 | 24.65] loss=3.19 avg=3.30\n",
            "[113 | 25.10] loss=3.54 avg=3.31\n",
            "[114 | 25.54] loss=3.12 avg=3.30\n",
            "[115 | 25.98] loss=3.34 avg=3.31\n",
            "[116 | 26.43] loss=3.13 avg=3.30\n",
            "[117 | 26.87] loss=2.87 avg=3.28\n",
            "[118 | 27.31] loss=3.47 avg=3.29\n",
            "[119 | 27.76] loss=3.35 avg=3.29\n",
            "[120 | 28.20] loss=3.58 avg=3.30\n",
            "[121 | 28.65] loss=3.34 avg=3.30\n",
            "[122 | 29.09] loss=3.24 avg=3.30\n",
            "[123 | 29.54] loss=3.60 avg=3.31\n",
            "[124 | 29.99] loss=3.20 avg=3.31\n",
            "[125 | 30.44] loss=3.42 avg=3.31\n",
            "[126 | 30.88] loss=3.36 avg=3.31\n",
            "[127 | 31.33] loss=3.38 avg=3.31\n",
            "[128 | 31.78] loss=3.36 avg=3.32\n",
            "[129 | 32.23] loss=3.32 avg=3.32\n",
            "[130 | 32.67] loss=2.91 avg=3.30\n",
            "[131 | 33.12] loss=3.26 avg=3.30\n",
            "[132 | 33.57] loss=3.24 avg=3.30\n",
            "[133 | 34.02] loss=3.20 avg=3.30\n",
            "[134 | 34.47] loss=3.68 avg=3.31\n",
            "[135 | 34.92] loss=3.13 avg=3.30\n",
            "[136 | 35.37] loss=3.22 avg=3.30\n",
            "[137 | 35.82] loss=3.05 avg=3.29\n",
            "[138 | 36.27] loss=3.08 avg=3.29\n",
            "[139 | 36.72] loss=3.28 avg=3.29\n",
            "[140 | 37.17] loss=3.17 avg=3.29\n",
            "[141 | 37.62] loss=3.32 avg=3.29\n",
            "[142 | 38.07] loss=3.25 avg=3.29\n",
            "[143 | 38.52] loss=3.45 avg=3.29\n",
            "[144 | 38.97] loss=3.25 avg=3.29\n",
            "[145 | 39.42] loss=3.21 avg=3.29\n",
            "[146 | 39.87] loss=3.16 avg=3.28\n",
            "[147 | 40.32] loss=3.15 avg=3.28\n",
            "[148 | 40.77] loss=3.03 avg=3.28\n",
            "[149 | 41.23] loss=3.28 avg=3.28\n",
            "[150 | 41.68] loss=3.31 avg=3.28\n",
            "[151 | 42.13] loss=3.16 avg=3.27\n",
            "[152 | 42.59] loss=3.39 avg=3.28\n",
            "[153 | 43.04] loss=3.19 avg=3.27\n",
            "[154 | 43.49] loss=3.08 avg=3.27\n",
            "[155 | 43.95] loss=3.26 avg=3.27\n",
            "[156 | 44.40] loss=3.37 avg=3.27\n",
            "[157 | 44.86] loss=3.13 avg=3.27\n",
            "[158 | 45.31] loss=3.03 avg=3.26\n",
            "[159 | 45.77] loss=3.57 avg=3.27\n",
            "[160 | 46.23] loss=3.13 avg=3.27\n",
            "[161 | 46.68] loss=3.18 avg=3.27\n",
            "[162 | 47.14] loss=3.33 avg=3.27\n",
            "[163 | 47.60] loss=2.93 avg=3.26\n",
            "[164 | 48.06] loss=2.93 avg=3.25\n",
            "[165 | 48.51] loss=3.72 avg=3.26\n",
            "[166 | 48.97] loss=3.12 avg=3.26\n",
            "[167 | 49.43] loss=3.26 avg=3.26\n",
            "[168 | 49.89] loss=2.91 avg=3.25\n",
            "[169 | 50.35] loss=3.45 avg=3.26\n",
            "[170 | 50.81] loss=3.11 avg=3.25\n",
            "[171 | 51.27] loss=3.71 avg=3.26\n",
            "[172 | 51.73] loss=3.07 avg=3.26\n",
            "[173 | 52.19] loss=3.07 avg=3.26\n",
            "[174 | 52.65] loss=3.33 avg=3.26\n",
            "[175 | 53.11] loss=3.33 avg=3.26\n",
            "[176 | 53.57] loss=3.49 avg=3.26\n",
            "[177 | 54.04] loss=3.30 avg=3.26\n",
            "[178 | 54.50] loss=3.36 avg=3.26\n",
            "[179 | 54.97] loss=3.27 avg=3.26\n",
            "[180 | 55.43] loss=3.40 avg=3.27\n"
          ]
        }
      ]
    }
  ]
}